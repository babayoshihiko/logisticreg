# ロジスティック回帰とは {#overview}

本章では、以下のことを学びます。

  1 どのような時にロジスティック回帰が使えるか
  2 応答変数とは何か
  3 説明変数とは何か
  4 オッズ比をどのように解釈するか
  5 フォレストプロットとは何か

1 フレイルになる、ならないという目的と関係がある因子(性別、運動習慣、社会参加、食事など)の複数の要因を同時に解析できるのが、ロジスティック回帰分析です。

2 この例として応答変数はフレイルになるかならないかです。

3 性別、運動習慣、社会参加、食事などの因子です。

## 独立して有意な変数の探索  {#finding-independent-significant-variables}

説明変数は、理想としては研究者が理論的に選択します。しかし、まだ探索段階であり、理論的に選ばれないような時もあります。

あるいは、予測因子の間に交絡があるかどうかを調べることが最大の関心の時もあります。

説明変数の数が多すぎると、真の関連性が薄まり、信頼区間が広く不正確な大きな標準誤差が生じたり、逆に誤った関連性が特定されることにつながります。

この場合のロジスティック回帰分析の流れは以下のようになります。

* 多くの説明変数を用意し、説明変数の間に相関関係があるものは、どれかひとつだけ選びます (多重共線性)。
* 単変量解析 (univariate logistic regression) を行う。単変量解析は、説明変数を一つだけにしたロジスティック回帰の場合もありますし、t 検定や $\chi^{2}$ などの場合もあります。
* 説明変数のうち、目的変数と相関関係がありそうなものだけ残します (通常、 p > 0.1)。
* 多重ロジスティック回帰を行い、調整済みオッズ比を求めます。

この方法は、まず多くの説明変数を用意し、数を減らしていくので、変数減少法 (Backward Elimination Method) と言います [@wang2007determination]。

このような選択法には、以下のものがあります。

* 変数減少法 (backward elimination)
* 変数増加法 (forward selection)
* 変数増減法 (stepwise with forward selection and/or backward elimination)

ややこしいことに、「ステップワイズ」と言う言葉は、３つ目だけをさして使う人もいれば、１つ目や２つ目にも使う人もいます。

数を減らす方法には、条件付き法、尤度比法、Wald 法などがあります。

変数選択法については、R の標準機能に関数があります [@zhang2016variable]。詳細は Chapter \@ref(predictables) で扱います。

さらには、ラッソ回帰 (Least Absolute Shrinkage and Selection Operator, LASSO) のような新たな手法もあります。LASSO を使った論文としては、糖尿病患者のフレイル予測をした論文があります [@bu2023development]。

## リスクスコアの開発と検証

ロジスティック回帰を使った応用例としては、リスクスコアの開発があります。リスクスコアとは、将来的なある疾患へのかかりやすさを、現時点でのデータから予測する一つの数値です。

リスクスコアの式は、ロジスティック回帰の式に非常によく似ています。

* 疾患の有無が分かっているデータを用意し、モデル作成用と検証用に分ける
* ロジスティック回帰により説明変数の調整済みオッズ比を求める
* リスクスコアの式を決定する
* 検証用データに対し、リスクスコアの精度を検証する

精度の検証に用いるのは、感度と特異度からなる ROC 曲線を用いることが多いようです。フレイルのリスクスコアの論文も多数ありますが、ROC を使っているものも [@ng2014frailty; @sundermann2011comprehensive]、使っていないものもあります [@gilbert2018development]。



