# ロジスティック回帰とは {#overview}

本章では、以下のことを学びます。
  - どのような時にロジスティック回帰が使えるか
  - 応答変数とは何か
  - 説明変数とは何か
  - オッズ比をどのように解釈するか
  - フォレストプロットとは何か

具体的には、実際の論文を読んで理解していきましょう。

## 独立して有意な変数の探索  {#finding-independent-significant-variables}

説明変数は、理想としては研究者が理論的に選択します。しかし、まだ探索段階であり、理論的に選ばれないような時もあります。

あるいは、予測因子の間に交絡があるかどうかを調べることが最大の関心の時もあります。

説明変数の数が多すぎると、真の関連性が薄まり、信頼区間が広く不正確な大きな標準誤差が生じたり、逆に誤った関連性が特定されることにつながります。

この場合のロジスティック回帰分析の流れは以下のようになります。

* 多くの説明変数を用意し、説明変数の間に相関関係があるものは、どれかひとつだけ選びます (多重共線性)。
* 単変量解析 (univariate logistic regression) を行う。単変量解析は、2x2の表からオッズ比を求めることとほぼ同じですが、少し異なります。
* 説明変数のうち、そう感がありそうなものだけ残します (通常、 p > 0.1)。
* 多重ロジスティック回帰を行い、調整済みオッズ比を求めます。

この方法は、まず多くの説明変数を用意し、数を減らしていくので、変数減少法 (Backward Elimination Method) と言います [@wang2007determination]。

このような選択法には、以下のものがあります。

* 変数減少法 (backward elimination)
* 変数増加法 (forward selection)
* 変数増減法 (stepwise with forward selection and/or backward elimination)

ややこしいことに、「ステップワイズ」と言う言葉は、３つ目だけをさして使う人もいれば、１つ目や２つ目にも使う人もいます。

さらには、ラッソ回帰 (Least Absolute Shrinkage and Selection Operator, LASSO) のような新たな手法もあります。LASSO を使った論文としては、糖尿病患者のフレイル予測をした論文があります [＠bu2023development]。
